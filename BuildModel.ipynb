{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Luong San Pham :  0.8071748878923767\n",
      "Dong goi :  0.8367346938775511\n",
      "Giao hang :  0.5581395348837209\n",
      "Cham soc khach hang :  0.6470588235294118\n",
      "Thiet ke :  0.12698412698412698\n",
      "Gia Ban :  0.11320754716981132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "df = pd.read_csv('cleaned_data_label.csv', sep=',')\n",
    "#lineList = [line.rstrip('\\n') for line in open('StopWord.txt',encoding=\"utf-8\")]\n",
    "#lineList.sort()\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "#df['comment_content'] = df['comment_content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (lineList)]))\n",
    "\n",
    "#target = ['Chat Luong San Pham','Dong goi','Giao hang','Cham soc khach hang','Thiet ke','Gia Ban','Pin','Do Nhay','Phu Kien','Nut Power','Con Lan','Ket Noi','Phi Ship']\n",
    "\n",
    "target = ['Chat Luong San Pham','Dong goi','Giao hang','Cham soc khach hang','Thiet ke','Gia Ban']\n",
    "\n",
    "for i in range(len(target)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['comment_content'], df[target[i]], test_size=0.25,\n",
    "                                                        stratify=df[target[i]], random_state=123456)\n",
    "    vectorizer = TfidfVectorizer(min_df=20)\n",
    "    vectors_train = vectorizer.fit_transform(X_train)\n",
    "    vectors_test = vectorizer.transform(X_test)\n",
    "    nbg = GaussianNB()\n",
    "    nbg.fit(vectors_train.toarray(), y_train)\n",
    "    predicted = nbg.predict(vectors_test.toarray())\n",
    "    accuracy = metrics.f1_score(y_test, predicted)\n",
    "    print(target[i],': ',accuracy)\n",
    "    #print(classification_report_imbalanced(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
